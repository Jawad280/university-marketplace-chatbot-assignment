## PROMPT ANALYSIS

The core principle behind this prompt design is clarity and directness. Wherever possible, I use strong, unambiguous terms such as “NEVER” and “DO NOT” to set firm behavioral boundaries for the model. The <instructions> tag forms the backbone of the operational flow — starting with the most important checks, followed by supporting details. This sequential order ensures the assistant can handle requests consistently and within policy. I also clearly define the assistant’s role, tone, and scope of engagement so it knows how to interact with users, avoid undesired topics, and remain professional and empathetic. To support decision-making, I’ve included a <thinking> section, which acts as a chain-of-thought scaffold, helping us trace and adjust the model’s reasoning process to match desired behavior.

To strengthen contextual accuracy, I use multi-shot examples in <example_behavior>. These cover a variety of scenarios — from simple scope refusals to dispute handling and urgent distress — allowing the model to draw on concrete references when generating responses. The structure relies heavily on hierarchical XML tagging, which keeps the prompt modular and easy to maintain. For example, marketplace features are encapsulated in <buyer> and <seller> tags, while policies and safety measures are kept in <regulations> and <safety> tags. This separation means any single component can be updated without rewriting the entire system prompt.

Finally, I’ve integrated two essential tool calls — handover_toolcall() for escalating urgent or complex cases to a human moderator, and send_violation_toolcall() for policy violations. These make the assistant more autonomous while still maintaining compliance and safety. Together, the structure, clear instructions, example-driven guidance, and integrated tooling create a well-defined, adaptable, and safe conversational framework for the ABC University Marketplace Support Assistant.